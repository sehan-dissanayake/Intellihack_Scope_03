{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fine-tuning - Intellihack Scope 03\n",
    "\n",
    "This notebook implements QLoRA fine-tuning for the Qwen 2.5-3B model on our generated QA pairs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Import Hugging Face modules\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "First, let's load our training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths\n",
    "qa_dir = Path('../data/qa_pairs')\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load datasets using Hugging Face datasets\n",
    "dataset = load_dataset('json', \n",
    "                       data_files={\n",
    "                           'train': str(qa_dir / 'train.json'),\n",
    "                           'validation': str(qa_dir / 'validation.json')\n",
    "                       })\n",
    "\n",
    "print(f\"Training examples: {len(dataset['train'])}\")\n",
    "print(f\"Validation examples: {len(dataset['validation'])}\")\n",
    "\n",
    "# Display a sample\n",
    "print(\"\\nSample training example:\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Base Model and Tokenizer\n",
    "\n",
    "We'll use Qwen 2.5-3B as our base model and configure it for 4-bit quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model parameters\n",
    "base_model_id = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "output_model_path = models_dir / \"qwen-3b-ai-research-qa\