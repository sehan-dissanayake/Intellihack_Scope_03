{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Pair Generation - Intellihack Scope 03\n",
    "\n",
    "This notebook focuses on generating high-quality question-answer pairs from the processed document chunks, which will be used for fine-tuning the Qwen 2.5-3B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load processed chunks\n",
    "processed_dir = Path('../data/processed')\n",
    "qa_dir = Path('../data/qa_pairs')\n",
    "qa_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(processed_dir / 'chunks.json', 'r', encoding='utf-8') as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(chunks)} document chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Generation Strategies\n",
    "\n",
    "We'll use rule-based templates to generate different types of questions:\n",
    "1. Definition questions (\"What is X?\")\n",
    "2. Explanation questions (\"How does X work?\")\n",
    "3. Comparison questions (\"Compare X and Y\")\n",
    "4. Technical detail questions (\"What are the components of X?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def extract_key_terms(text):\n",
    "    \"\"\"\n",
    "    Extract potential key terms from text using simple heuristics.\n",
    "    \"\"\"\n",
    "    # Find capitalized terms (potential proper nouns)\n",
    "    capitalized = re.findall(r'\\b[A-Z][a-zA-Z0-9]+([-][A-Za-z0-9]+)*\\b', text)\n",
    "    \n",
    "    # Find terms in quotes\n",
    "    quoted = re.findall(r'\"([^\"]+)\"', text)\n",
    "    \n",
    "    # Find technical terms (containing numbers, hyphens, etc.)\n",
    "    technical = re.findall(r'\\b[A-Za-z][A-Za-z0-9]*[-][A-Za-z0-9]+\\b', text)\n",
    "    \n",
    "    # Combine and deduplicate\n",
    "    all_terms = list(set(capitalized + quoted + technical))\n",
    "    \n",
    "    # Filter out common words and very short terms\n",
    "    common_words = {'the', 'and', 'for', 'with', 'this', 'that', 'these', 'those'}\n",
    "    filtered_terms = [term for term in all_terms if term.lower() not in common_words and len(term) > 3]\n",
    "    \n",
    "    return filtered_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_qa_pairs(chunk):\n",
    "    \"\"\"\n",
    "    Generate question-answer pairs from a document chunk.\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    content = chunk['content']\n",
    "    topic = chunk['topic']\n",
    "    \n",
    "    # Extract potential terms to ask about\n",
    "    key_terms = extract_key_terms(content)\n",
    "    \n",
    "    # If no key terms found, use the topic itself\n",
    "    if not key_terms and topic:\n",
    "        key_terms = [topic]\n",
    "    \n",
    "    # Generate different question types\n",
    "    for term in key_terms[:3]:  # Limit to 3 terms per chunk to avoid repetition\n",
    "        # Definition question\n",
    "        qa_pairs.append({\n",
    "            \"question\": f\"What is {term}?\",\n",
    "            \"answer\": content,  # Using full chunk as answer\n",
    "            \"source\": chunk['source'],\n",
    "            \"chunk_id\": chunk['chunk_id'],\n",
    "            \"question_type\": \"definition\"\n",
    "        })\n",
    "        \n",
    "        # Technical details question\n",
    "        qa_pairs.append({\n",
    "            \"question\": f\"Explain the technical details of {term}.\",\n",
    "            \"answer\": content,\n",
    "            \"source\": chunk['source'],\n",
    "            \"chunk_id\": chunk['chunk_id'],\n",
    "            \"question_type\": \"technical\"\n",
    "        })\n",
    "        \n",
    "        # Use case question\n",
    "        qa_pairs.append({\n",
    "            \"question\": f\"What are the applications or benefits of {term}?\",\n",
    "            \"answer\": content,\n",
    "            \"source\": chunk['source'],\n",
    "            \"chunk_id\": chunk['chunk_id'],\n",
    "            \"question_type\": \"application\"\n",
    "        })\n",
    "    \n",
    "    # Add a general question about the topic\n",
    "    qa_pairs.append({\n",
    "        \"question\": f\"Describe the key aspects of {topic}.\",\n",
    "        \"answer\": content,\n",
    "        \"source\": chunk['source'],\n",
    "        \"chunk_id\": chunk['chunk_id'],\n",
    "        \"question_type\": \"description\"\n",
    "    })\n",
    "    \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate QA pairs from all chunks\n",
    "all_qa_pairs = []\n",
    "\n",
    "for chunk in tqdm(chunks, desc=\"Generating QA pairs\"):\n",
    "    pairs = generate_qa_pairs(chunk)\n",
    "    all_qa_pairs.extend(pairs)\n",
    "\n",
    "# Convert to DataFrame\n",
    "qa_df = pd.DataFrame(all_qa_pairs)\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Generated {len(qa_df)} QA pairs\")\n",
    "print(f\"Question types: {qa_df['question_type'].value_counts().to_dict()}\")\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format QA Pairs for Fine-tuning\n",
    "\n",
    "Now we'll format the QA pairs into the specific format required by the Qwen 2.5-3B model for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def format_for_finetuning(qa_pair):\n",
    "    \"\"\"\n",
    "    Format QA pairs for Qwen 2.5-3B fine-tuning using chat template.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": qa_pair['question']},\n",
    "            {\"role\": \"assistant\", \"content\": qa_pair['answer']}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Format all QA pairs\n",
    "formatted_data = [format_for_finetuning(qa_pair) for qa_pair in qa_df.to_dict(orient='records')]\n",
    "\n",
    "# Split into train and validation sets (90% train, 10% validation)\n",
    "random.shuffle(formatted_data)\n",
    "split_idx = int(len(formatted_data) * 0.9)\n",
    "\n",
    "train_data = formatted_data[:split_idx]\n",
    "val_data = formatted_data[split_idx:]\n",
    "\n",
    "# Save the datasets\n",
    "with open(qa_dir / \"train.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, indent=2)\n",
    "    \n",
    "with open(qa_dir / \"validation.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(val_data, f, indent=2)\n",
    "    \n",
    "print(f\"Saved {len(train_data)} training examples and {len(val_data)} validation examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample QA Pairs\n",
    "\n",
    "Let's examine some sample QA pairs to ensure quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display 3 random examples\n",
    "sample_indices = random.sample(range(len(formatted_data)), 3)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    sample = formatted_data[idx]\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Example {idx}:\")\n",
    "    print(f\"Question: {sample['messages'][0]['content']}\")\n",
    "    print(\"\\nAnswer (truncated): \")\n",
    "    print(sample['messages'][1]['content'][:300], \"...\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}